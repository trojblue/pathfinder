{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2132d7c1-4002-4edf-8c71-ab3ff24a8f95",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "from typing import Union\n",
    "\n",
    "from fourdimensions.appapi.utils.auth import enc_data\n",
    "from fourdimensions.appapi.const import DEFAULT_HEADER\n",
    "\n",
    "class Detail:\n",
    "    @staticmethod\n",
    "    def get(item_id: Union[str, int], sess: requests.Session = None) -> dict:\n",
    "        assert isinstance(item_id, (str, int))\n",
    "        url = \"https://api-hl.bcy.net/apiv2/item/detail\"\n",
    "        params = {\n",
    "            \"item_id\": item_id,\n",
    "        }\n",
    "        enced_data = enc_data(json.dumps(params, separators=(\",\", \":\")))\n",
    "        real_params = {\n",
    "            \"data\": enced_data,\n",
    "        }\n",
    "        r = sess.post(url, data=real_params)\n",
    "        r.raise_for_status()\n",
    "        return r.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "73088dbc-dbd6-49ef-ac30-04b9732d07e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    sess = requests.Session()\n",
    "    sess.headers.update(DEFAULT_HEADER)\n",
    "    detail = Detail.get(\n",
    "            item_id=7215077620059216956,\n",
    "            sess=sess,\n",
    "            )\n",
    "    with open(\"detail-demo.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(detail, f, indent=4, ensure_ascii=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cb5a9e5a-ddd6-4592-a59f-0b246460fcf1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "21876545-aea6-4a8a-bfce-73d7b6ceeeed",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from typing import Dict\n",
    "\n",
    "def parse_json_to_df(json_dict: Dict) -> pd.DataFrame:\n",
    "    data = {\n",
    "        'user_id': json_dict['user']['id'],\n",
    "        'name': json_dict['user']['name'],\n",
    "        #'utags': \"###\".join(json_dict['user']['utags']),\n",
    "        'post_id': json_dict['post']['id'],\n",
    "        'tags': \"###\".join(json_dict['post']['tags']),\n",
    "        'date': json_dict['post']['date'],\n",
    "        'parody': json_dict['post']['parody'],\n",
    "        'content': json_dict['post']['content'],\n",
    "        'likes': json_dict['post']['likes'],\n",
    "        'shares': json_dict['post']['shares'],\n",
    "        'replies': json_dict['post']['replies'],\n",
    "        'type': json_dict['post']['image_list'][0]['type'],\n",
    "        'mid': json_dict['post']['image_list'][0]['mid'],\n",
    "        'w': json_dict['post']['image_list'][0]['w'],\n",
    "        'h': json_dict['post']['image_list'][0]['h'],\n",
    "        'original_path': json_dict['post']['image_list'][0]['original_path'],\n",
    "        'visible_level': json_dict['post']['image_list'][0]['visible_level'],\n",
    "        'format': json_dict['post']['image_list'][0]['format'],\n",
    "        # 'collection_title': json_dict['collection']['title'],\n",
    "        # 'collection_id': json_dict['collection']['collection_id'],\n",
    "        # 'prev_id': json_dict['collection']['prev_post']['item_id'],\n",
    "        # 'next_id': json_dict['collection']['next_post']['item_id'],\n",
    "        # 'collection_user_id': json_dict['collection']['user']['uid'],\n",
    "        'category': json_dict['category'],\n",
    "        'subcategory': json_dict['subcategory'],\n",
    "        'num': json_dict['num'],\n",
    "        'id': json_dict['id'],\n",
    "        'width': json_dict['width'],\n",
    "        'height': json_dict['height'],\n",
    "        'filename': json_dict['filename'],\n",
    "        'extension': json_dict['extension'],\n",
    "        'filter': json_dict['filter'],\n",
    "        'orig_path': json_dict['orig_path']\n",
    "    }\n",
    "    \n",
    "    return pd.DataFrame([data])\n",
    "\n",
    "# Usage:\n",
    "# df = parse_json_to_df(json_dict)\n",
    "# df.to_parquet('output.parquet')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ec9408e7-d615-49ce-a450-39f846d550e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'str'>\n",
      "{'user': {'id': 1037581441053848, 'name': '木甘牌甘木_', 'avatar': 'https://img-bcy-qn.pstatp.com/8a6c7b1cfcf041ec9a5fa2000d14b3c1', 'utags': ['绘师', '娃妈', '猫控']}, 'post': {'id': 7215077620059216956, 'tags': ['稿件展示', '孩厨', 'OC', '孩厨交流中心', '不是我画的', '约稿', '时之庭的回响', '自家OC', '绘画', '海伦娜HELENA'], 'date': '2023-03-27 04:26:06', 'parody': '', 'content': '旅途中，海伦娜会接受一些冒险协会的赏金委托——通常都是采集一些稀有罕见的材料，或者去寻找［传说］的痕迹。<br>  这一次，她正在寻找一种传说中的，能够让人回想起最美好记忆的奇迹之花……', 'likes': 113, 'shares': 0, 'replies': 8, 'image_list': [{'path': 'https://p3-bcy-sign.bcyimg.com/banciyuan/fd00f46128e74ca19cd1ec5d1308d9d1~tplv-banciyuan-w650.image?x-expires=1702771281&x-signature=up4kg1nUesFET19nNMsF0WzWzVo%3D', 'type': 'image', 'mid': 228660350, 'w': 1440, 'h': 900, 'original_path': 'https://p3-bcy-sign.bcyimg.com/banciyuan/fd00f46128e74ca19cd1ec5d1308d9d1~noop.image?x-expires=1702771280&x-signature=zElBj8O2O9UtyHMqQmOvwcMSjQg%3D', 'visible_level': '', 'ratio': 0, 'origin': 'https://p3-bcy-sign.bcyimg.com/banciyuan/fd00f46128e74ca19cd1ec5d1308d9d1~tplv-bcyx-yuan-logo-v1:wqnmnKjnlJjniYznlJjmnKhfCuWNiuasoeWFgyAtIEFDR-eIseWlveiAheekvuWMug==.image?x-expires=1702771281&x-signature=vOM3eXdvHKCiTXh6INjLtX2k8Rk%3D', 'format': 'jpeg'}]}, 'collection': {'title': '🦋海伦娜Helena', 'collection_id': 6294915, 'prev_post': {'item_id': '7206320155058510903', 'type': 'note', 'visible_status': 1}, 'next_post': {'item_id': '7243782473006455863', 'type': 'note', 'visible_status': 1}, 'user': {'uid': 1037581441053848}, 'bSubscribed': False, 'collection_type': 'mixed', 'collection_item_ctime': 0, 'collection_item_ot': 0}, 'item_like_users': [{'uname': '知槿-淡圈版', 'uid': 3161822169413870}, {'uname': '子俞七晴.', 'uid': 817648588299309}, {'uname': '傅莱合富贵', 'uid': 1781650409138424}], 'category': 'bcy', 'subcategory': 'post', 'num': 1, 'id': 228660350, 'width': 1440, 'height': 900, 'filename': 'fd00f46128e74ca19cd1ec5d1308d9d1', 'extension': 'jpg', 'filter': 'noop', 'orig_path': 'https://p3-bcy-sign.bcyimg.com/banciyuan/fd00f46128e74ca19cd1ec5d1308d9d1~noop.image?x-expires=1702771281&x-signature=LgFK%2BA0LKB0fy7qzBHwnyFsc5j8%3D'}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "# reads json\n",
    "with open(r\"/home/studio-lab-user/dev/gdld/gallery-dl/1037581441053848###木甘牌甘木_/7215077620059216956###228660350.jpg.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "    data = f.read()\n",
    "    \n",
    "print(type(data))\n",
    "json_dict = json.loads(data)\n",
    "print(json_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a290247d-e5f8-4be5-891e-5c4841919f07",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>name</th>\n",
       "      <th>utags</th>\n",
       "      <th>post_id</th>\n",
       "      <th>tags</th>\n",
       "      <th>date</th>\n",
       "      <th>parody</th>\n",
       "      <th>content</th>\n",
       "      <th>likes</th>\n",
       "      <th>shares</th>\n",
       "      <th>...</th>\n",
       "      <th>category</th>\n",
       "      <th>subcategory</th>\n",
       "      <th>num</th>\n",
       "      <th>id</th>\n",
       "      <th>width</th>\n",
       "      <th>height</th>\n",
       "      <th>filename</th>\n",
       "      <th>extension</th>\n",
       "      <th>filter</th>\n",
       "      <th>orig_path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1037581441053848</td>\n",
       "      <td>木甘牌甘木_</td>\n",
       "      <td>绘师###娃妈###猫控</td>\n",
       "      <td>7215077620059216956</td>\n",
       "      <td>稿件展示###孩厨###OC###孩厨交流中心###不是我画的###约稿###时之庭的回响#...</td>\n",
       "      <td>2023-03-27 04:26:06</td>\n",
       "      <td></td>\n",
       "      <td>旅途中，海伦娜会接受一些冒险协会的赏金委托——通常都是采集一些稀有罕见的材料，或者去寻找［传...</td>\n",
       "      <td>113</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>bcy</td>\n",
       "      <td>post</td>\n",
       "      <td>1</td>\n",
       "      <td>228660350</td>\n",
       "      <td>1440</td>\n",
       "      <td>900</td>\n",
       "      <td>fd00f46128e74ca19cd1ec5d1308d9d1</td>\n",
       "      <td>jpg</td>\n",
       "      <td>noop</td>\n",
       "      <td>https://p3-bcy-sign.bcyimg.com/banciyuan/fd00f...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            user_id    name         utags              post_id  \\\n",
       "0  1037581441053848  木甘牌甘木_  绘师###娃妈###猫控  7215077620059216956   \n",
       "\n",
       "                                                tags                 date  \\\n",
       "0  稿件展示###孩厨###OC###孩厨交流中心###不是我画的###约稿###时之庭的回响#...  2023-03-27 04:26:06   \n",
       "\n",
       "  parody                                            content  likes  shares  \\\n",
       "0         旅途中，海伦娜会接受一些冒险协会的赏金委托——通常都是采集一些稀有罕见的材料，或者去寻找［传...    113       0   \n",
       "\n",
       "   ...  category subcategory  num         id  width height  \\\n",
       "0  ...       bcy        post    1  228660350   1440    900   \n",
       "\n",
       "                           filename extension filter  \\\n",
       "0  fd00f46128e74ca19cd1ec5d1308d9d1       jpg   noop   \n",
       "\n",
       "                                           orig_path  \n",
       "0  https://p3-bcy-sign.bcyimg.com/banciyuan/fd00f...  \n",
       "\n",
       "[1 rows x 33 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parse_json_to_df(json_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "cb4486e9-a26d-4ca1-99d2-fde7e54feb07",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import tarfile\n",
    "import shutil\n",
    "import pandas as pd\n",
    "from typing import List\n",
    "from glob import glob\n",
    "\n",
    "class JSONProcessor:\n",
    "    def __init__(self, user_infos: str):\n",
    "        self.user_infos = user_infos\n",
    "        if not os.path.exists(user_infos):\n",
    "            os.makedirs(user_infos)\n",
    "\n",
    "    def process(self, directory: str) -> None:\n",
    "        if not os.path.exists(directory):\n",
    "            raise FileNotFoundError(f\"The directory {directory} does not exist.\")\n",
    "            \n",
    "        df = self._load_and_combine_json(directory)\n",
    "        if df.empty:\n",
    "            print(f\"No JSON data found in {directory}.\")\n",
    "            return\n",
    "\n",
    "        self._save_as_parquet(df, directory)\n",
    "        self._copy_info_json(directory)\n",
    "        self._rename_associated_jsons(directory)\n",
    "        self._compress_and_delete_directory(directory)\n",
    "\n",
    "    def _load_and_combine_json(self, directory: str) -> pd.DataFrame:\n",
    "        json_files = glob(os.path.join(directory, \"*.json\"))\n",
    "        json_files = [file for file in json_files if \"info.json\" not in file]\n",
    "\n",
    "        data_frames = []\n",
    "        for file in json_files:\n",
    "            with open(file, 'r') as f:\n",
    "                data = json.load(f)\n",
    "                df = parse_json_to_df(data)  # Your original function\n",
    "                data_frames.append(df)\n",
    "\n",
    "        if not data_frames:\n",
    "            return pd.DataFrame()  # Empty DataFrame\n",
    "\n",
    "        combined_df = pd.concat(data_frames, ignore_index=True)\n",
    "        return combined_df\n",
    "\n",
    "    def _save_as_parquet(self, df: pd.DataFrame, directory: str) -> None:\n",
    "        parquet_path = f\"{directory}.parquet\"\n",
    "        df.to_parquet(parquet_path)\n",
    "\n",
    "    def _copy_info_json(self, directory: str) -> None:\n",
    "        src = os.path.join(directory, \"info.json\")\n",
    "        if not os.path.isfile(src):\n",
    "            print(f\"info.json does not exist in {directory}.\")\n",
    "            return\n",
    "\n",
    "        directory_name = os.path.basename(directory)\n",
    "        dest = os.path.join(self.user_infos, f\"{directory_name}_info.json\")\n",
    "        shutil.copy2(src, dest)\n",
    "\n",
    "    def _rename_associated_jsons(self, directory: str) -> None:\n",
    "        all_files = glob(os.path.join(directory, \"*\"))\n",
    "        for file in all_files:\n",
    "            basename = os.path.basename(file)\n",
    "            json_file = f\"{file}.json\"\n",
    "            if basename.endswith(\".jpg\") and os.path.isfile(json_file):\n",
    "                try:\n",
    "                    os.rename(json_file, file.replace(\".jpg\", \".json\"))\n",
    "                except Exception as e:\n",
    "                    print(f\"Failed to rename {json_file}: {e}\")\n",
    "                \n",
    "    def _compress_and_delete_directory(self, directory: str) -> None:\n",
    "        try:\n",
    "            with tarfile.open(f\"{directory}.tar\", \"w\") as tar:\n",
    "                tar.add(directory, arcname=os.path.basename(directory))\n",
    "        except Exception as e:\n",
    "            print(f\"Failed to compress {directory}: {e}\")\n",
    "            return\n",
    "        \n",
    "        try:\n",
    "            shutil.rmtree(directory)\n",
    "        except Exception as e:\n",
    "            print(f\"Failed to delete {directory}: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "13c3e045-82d6-4ba1-bdb2-1140a535de5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "processor = JSONProcessor(user_infos=\"./user_infos\")\n",
    "processor.process(\"/home/studio-lab-user/dev/gdld/gallery-dl/1037581441053848###木甘牌甘木_2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5453da80-b213-40c7-a44b-d49fdc9dbed2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "310:Python",
   "language": "python",
   "name": "conda-env-310-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
